{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c22441-db13-4415-a605-a9a1d99ee83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from hw3_helpers import get_data, Classifier, evaluate, train_one_epoch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa15c19-02c0-4af3-88af-c5403b2e35c3",
   "metadata": {},
   "source": [
    "Create training, validation and testing dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4c2f1e-69c1-49d9-9b99-4a302b1552f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:41: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `transforms.Compose([transforms.ToImageTensor(), transforms.ConvertImageDtype()])`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, val_dataloader = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1eda371-ddc0-4978-8525-760f34e847c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba52ec7-52a3-4b6a-9c37-8037990bdf4b",
   "metadata": {},
   "source": [
    "Creating the bulding blocks of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5cafe-8510-4eaa-9be5-413d21eb5bc4",
   "metadata": {},
   "source": [
    "Initialize the model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f9435-85ec-4450-9449-9a2223e6d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_initial_filters = 64; n_stages = 12; blocks_per_stage = 1\n",
    "model = Classifier(n_initial_filters, n_stages, blocks_per_stage)\n",
    "model.to(dev)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d53088d-ab97-4bf8-8453-95deb72e7cbb",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9340a98a-e1ba-4cdd-9af2-094571a8f43b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 30\n",
    "cols = [\"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"]\n",
    "training_frame = {col: [] for col in cols}\n",
    "for j in range(epochs):\n",
    "    train_one_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "    train_acc, train_loss = evaluate(train_dataloader, model, loss_fn) \n",
    "    print(f\"Epoch {j}: train loss: {train_loss:.3f}, accuracy: {train_acc:.3f}\" )\n",
    "    val_acc, val_loss = evaluate(val_dataloader, model, loss_fn)\n",
    "    print(f\"Epoch {j}: validation loss: {val_loss:.3f}, accuracy: {val_acc:.3f}\")\n",
    "    training_frame[\"train_loss\"].append(train_loss), training_frame[\"train_acc\"].append(train_acc)\n",
    "    training_frame[\"val_loss\"].append(val_loss), training_frame[\"val_acc\"].append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead5d956-d409-452b-8695-038949e5690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_frame = pd.DataFrame(training_frame)\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "title = f\"n_initial_filters: {n_initial_filters}, n_stages: {n_stages}, blocks_per_stage: {blocks_per_stage}\"\n",
    "title += \"\\n conv_filter_size reduced to 7 -> 3, increased initial stride: 1 -> 2, added a lr scheduler\\n\"\n",
    "plt.suptitle(title)\n",
    "training_frame.plot(y=[\"train_loss\", \"val_loss\"], ax=axs[0], xlabel='Epochs', title=\"Loss\")\n",
    "training_frame.plot(y=[\"train_acc\", \"val_acc\"], ax=axs[1], xlabel='Epochs', title=\"Accuracy\")\n",
    "plt.tight_layout()\n",
    "plt.show(fig)\n",
    "plot = f'nif={n_initial_filters}_nstg={n_stages}_blks={blocks_per_stage}_lr_schedule'\n",
    "fig.savefig(f'{plot}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca25fc-5e5a-4ef1-94ac-82d0c52ac0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_frame = pd.DataFrame(training_frame)\n",
    "# fig, axs = plt.subplots(ncols=2)\n",
    "# title = f\"n_initial_filters: {n_initial_filters}, n_stages: {n_stages}, blocks_per_stage: {blocks_per_stage}\"\n",
    "# title += \"\\n conv_filter_size reduced to 7 -> 3, increased initial stride: 1 -> 2\"\n",
    "# plt.suptitle(title)\n",
    "# training_frame.plot(y=[\"train_loss\", \"val_loss\"], ax=axs[0], xlabel='Epochs', title=\"Loss\")\n",
    "# training_frame.plot(y=[\"train_acc\", \"val_acc\"], ax=axs[1], xlabel='Epochs', title=\"Accuracy\")\n",
    "# plt.show(fig)\n",
    "# plot = f'nif={n_initial_filters}_nstg={n_stages}_blks={blocks_per_stage}_2'\n",
    "# fig.savefig(f'{plot}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71daafb1-da42-4e31-9db1-9b9aa020eca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the results of the original model. \n",
      "Clearly, the model is overfitting as the validation_accuracy has saturated at value smaller than training_accuracy.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'original_model.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/IPython/core/display.py:1045\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/IPython/core/formatters.py:974\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    971\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 974\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/IPython/core/display.py:1035\u001b[0m, in \u001b[0;36mImage._repr_mimebundle_\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m   1034\u001b[0m     mimetype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mimetype\n\u001b[0;32m-> 1035\u001b[0m     data, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43malways_both\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[1;32m   1037\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {mimetype: metadata}\n",
      "File \u001b[0;32m/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/IPython/core/display.py:1047\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1047\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: 'original_model.png'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: 'original_model.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/IPython/core/display.py:1045\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m \u001b[43mb2a_base64\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/IPython/core/formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/IPython/core/display.py:1067\u001b[0m, in \u001b[0;36mImage._repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_png_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FMT_PNG:\n\u001b[0;32m-> 1067\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/soft/datascience/conda/2023-10-04/mconda3/lib/python3.10/site-packages/IPython/core/display.py:1047\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[0;34m(self, always_both)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1047\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: 'original_model.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#original model\n",
    "# 64, 4, 2\n",
    "string = \"\"\"These are the results of the original model. \n",
    "Clearly, the model is overfitting as the validation_accuracy has saturated at value smaller than training_accuracy.\"\"\"\n",
    "print(string)\n",
    "Image(\"original_model.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36a0b5c-e987-4366-94a5-47e43fa54aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_initial_filers halved, num_stages halved\n",
    "string = \"\"\"To reduce overfitting, we reduce the num_parameters in the model by:\n",
    "1.) Halving the intial_filters from 64 to 32\n",
    "2.) Halving the number of stages from 4 to 2\n",
    "Clearly, the model is still overfitting as the validation_accuracy has saturated at value smaller than training_accuracy.\"\"\"\n",
    "print(string)\n",
    "Image(\"reduced_size_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acce373-4c75-4e3b-b154-3fd2f250dad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience/conda-2023-01-10",
   "language": "python",
   "name": "conda-2023-01-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
