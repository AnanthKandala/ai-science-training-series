{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91075118-883f-4952-b411-2478a3bbd346",
   "metadata": {},
   "source": [
    "CEREBRAS log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ae2bb-c5d2-4879-bd46-302945197bc6",
   "metadata": {},
   "source": [
    "| Batch Size | Final Loss | Processed Samples | Run Time (seconds) |\n",
    "|------------|------------|-------------------|---------------------|\n",
    "| 1024       | 7.07812    | 1024000           | 210.338430415       |\n",
    "| 512        | 7.12500    | 512000            | 175.636380857       |\n",
    "| 2048       | 7.14844    | 2048000           | 304.146350184       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06039a8-1071-4f78-a919-6ee1a5692634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (venv_cerebras_pt) [swimzebra@cer-login-02 bert]$ python run.py CSX --job_labels name=bert_pt \\--params configs/bert_large_MSL128_sampleds.yaml \\--num_workers_per_csx=1 --mode train \\--model_dir $MODEL_DIR --mount_dirs /home/ /software/ \\--python_paths /home/$(whoami)/R_2.1.1/modelzoo/ \\--compile_dir $(whoami) |& tee mytest.log\n",
    "# 2024-04-07 20:25:49,267 INFO:   Effective batch size is 1024.\n",
    "# 2024-04-07 20:25:49,292 INFO:   Checkpoint autoloading is enabled. Looking for latest checkpoint in \"model_dir_bert_large_pytorch\" directory with the following naming convention: `checkpoint_(step)(_timestamp)?.mdl`.\n",
    "# 2024-04-07 20:25:49,294 INFO:   No checkpoints were found in \"model_dir_bert_large_pytorch\".\n",
    "# 2024-04-07 20:25:49,294 INFO:   No checkpoint was provided. Using randomly initialized model parameters.\n",
    "# 2024-04-07 20:25:50,542 INFO:   Saving checkpoint at step 0\n",
    "# 2024-04-07 20:26:18,445 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_0.mdl\n",
    "# 2024-04-07 20:26:33,107 INFO:   Compiling the model. This may take a few minutes.\n",
    "# 2024-04-07 20:26:33,108 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.\n",
    "# 2024-04-07 20:26:34,326 INFO:   Initiating a new image build job against the cluster server.\n",
    "# 2024-04-07 20:26:34,436 INFO:   Custom worker image build is disabled from server.\n",
    "# 2024-04-07 20:26:34,443 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.\n",
    "# 2024-04-07 20:26:34,780 INFO:   Initiating a new compile wsjob against the cluster server.\n",
    "# 2024-04-07 20:26:34,902 INFO:   compile job id: wsjob-f6xu8wdfovwkfm3s3akzy2, remote log path: /n1/wsjob/workdir/job-operator/wsjob-f6xu8wdfovwkfm3s3akzy2\n",
    "# 2024-04-07 20:26:44,947 INFO:   Poll ingress status: Waiting for job running, current job status: Queueing, msg: job is queueing. Job queue status: current job is top of queue but likely blocked by running jobs, 1 compile job(s) running using 67Gi memory. For more information, please run 'csctl get jobs'.\n",
    "# 2024-04-07 20:36:35,233 INFO:   Poll ingress status: Waiting for job running, current job status: Queueing, msg: job is queueing. Job queue status: current job is top of queue but likely blocked by running jobs, 1 execute job(s) running using 1 system(s), 1 compile job(s) running using 67Gi memory. For more information, please run 'csctl get jobs'.\n",
    "# 2024-04-07 20:36:45,245 INFO:   Poll ingress status: Waiting for job service readiness.\n",
    "# 2024-04-07 20:37:15,286 INFO:   Ingress is ready: Job ingress ready, poll ingress success.\n",
    "# 2024-04-07 20:37:19,857 INFO:   Pre-optimization transforms...\n",
    "# 2024-04-07 20:37:26,429 INFO:   Optimizing layouts and memory usage...\n",
    "# 2024-04-07 20:37:26,494 INFO:   Gradient accumulation enabled\n",
    "# 2024-04-07 20:37:26,498 INFO:   Gradient accumulation trying sub-batch size 128...\n",
    "# 2024-04-07 20:37:29,538 INFO:   Exploring floorplans\n",
    "# 2024-04-07 20:37:40,452 INFO:   Exploring data layouts\n",
    "# 2024-04-07 20:38:01,477 INFO:   Optimizing memory usage\n",
    "# 2024-04-07 20:38:30,407 INFO:   Gradient accumulation picked sub-batch size 128 with 3 lanes\n",
    "\n",
    "# 2024-04-07 20:38:30,443 INFO:   Post-layout optimizations...\n",
    "# 2024-04-07 20:38:38,043 INFO:   Allocating buffers...\n",
    "# 2024-04-07 20:38:40,429 INFO:   Code generation...\n",
    "# 2024-04-07 20:38:54,166 INFO:   Compiling image...\n",
    "# 2024-04-07 20:38:54,172 INFO:   Compiling kernels\n",
    "# ^C\n",
    "# (venv_cerebras_pt) [swimzebra@cer-login-02 bert]$ vi configs/bert_large_MSL128_sampleds.yaml \n",
    "# (venv_cerebras_pt) [swimzebra@cer-login-02 bert]$ export MODEL_DIR=model_dir_bert_large_pytorch\n",
    "# (venv_cerebras_pt) [swimzebra@cer-login-02 bert]$ if [ -d \"$MODEL_DIR\" ]; then rm -Rf $MODEL_DIR; fi\n",
    "# (venv_cerebras_pt) [swimzebra@cer-login-02 bert]$ python run.py CSX --job_labels name=bert_pt \\--params configs/bert_large_MSL128_sampleds.yaml \\--num_workers_per_csx=1 --mode train \\--model_dir $MODEL_DIR --mount_dirs /home/ /software/ \\--python_paths /home/$(whoami)/R_2.1.1/modelzoo/ \\--compile_dir $(whoami) |& tee mytest.log\n",
    "# 2024-04-07 20:40:59,125 INFO:   Effective batch size is 1024.\n",
    "# 2024-04-07 20:40:59,149 INFO:   Checkpoint autoloading is enabled. Looking for latest checkpoint in \"model_dir_bert_large_pytorch\" directory with the following naming convention: `checkpoint_(step)(_timestamp)?.mdl`.\n",
    "# 2024-04-07 20:40:59,151 INFO:   No checkpoints were found in \"model_dir_bert_large_pytorch\".\n",
    "# 2024-04-07 20:40:59,151 INFO:   No checkpoint was provided. Using randomly initialized model parameters.\n",
    "# 2024-04-07 20:41:00,439 INFO:   Saving checkpoint at step 0\n",
    "# 2024-04-07 20:41:28,501 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_0.mdl\n",
    "# 2024-04-07 20:41:43,139 INFO:   Compiling the model. This may take a few minutes.\n",
    "# 2024-04-07 20:41:43,140 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.\n",
    "# 2024-04-07 20:41:44,377 INFO:   Initiating a new image build job against the cluster server.\n",
    "# 2024-04-07 20:41:44,497 INFO:   Custom worker image build is disabled from server.\n",
    "# 2024-04-07 20:41:44,504 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.\n",
    "# 2024-04-07 20:41:44,868 INFO:   Initiating a new compile wsjob against the cluster server.\n",
    "# 2024-04-07 20:41:44,996 INFO:   compile job id: wsjob-bfsdwnrotkwahux9h9yzqr, remote log path: /n1/wsjob/workdir/job-operator/wsjob-bfsdwnrotkwahux9h9yzqr\n",
    "# 2024-04-07 20:41:55,044 INFO:   Poll ingress status: Waiting for job service readiness.\n",
    "# 2024-04-07 20:42:25,043 INFO:   Ingress is ready: Job ingress ready, poll ingress success.\n",
    "# 2024-04-07 20:42:29,060 INFO:   Pre-optimization transforms...\n",
    "# 2024-04-07 20:42:34,859 INFO:   Optimizing layouts and memory usage...\n",
    "# 2024-04-07 20:42:34,917 INFO:   Gradient accumulation disabled\n",
    "# 2024-04-07 20:42:39,609 INFO:   Exploring floorplans\n",
    "# 2024-04-07 20:42:41,358 INFO:   Exploring data layouts\n",
    "# 2024-04-07 20:43:12,625 INFO:   Optimizing memory usage\n",
    "# 2024-04-07 20:43:35,475 INFO:   Post-layout optimizations...\n",
    "# 2024-04-07 20:43:43,815 INFO:   Allocating buffers...\n",
    "# 2024-04-07 20:43:47,200 INFO:   Code generation...\n",
    "# 2024-04-07 20:44:08,423 INFO:   Compiling image...\n",
    "# 2024-04-07 20:44:08,429 INFO:   Compiling kernels\n",
    "# 2024-04-07 20:46:15,935 INFO:   Compiling final image\n",
    "# 2024-04-07 20:49:15,007 INFO:   Compile artifacts successfully written to remote compile directory. Compile hash is: cs_6294237297756385158\n",
    "# 2024-04-07 20:49:15,075 INFO:   Heartbeat thread stopped for wsjob-bfsdwnrotkwahux9h9yzqr.\n",
    "# 2024-04-07 20:49:15,078 INFO:   Compile was successful!\n",
    "# 2024-04-07 20:49:15,084 INFO:   Programming Cerebras Wafer Scale Cluster for execution. This may take a few minutes.\n",
    "# 2024-04-07 20:49:17,516 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.\n",
    "# 2024-04-07 20:49:17,889 INFO:   Initiating a new execute wsjob against the cluster server.\n",
    "# 2024-04-07 20:49:18,024 INFO:   execute job id: wsjob-fambxt9dpjfxuunmtq4u4t, remote log path: /n1/wsjob/workdir/job-operator/wsjob-fambxt9dpjfxuunmtq4u4t\n",
    "# 2024-04-07 20:49:28,073 INFO:   Poll ingress status: Waiting for job running, current job status: Scheduled, msg: job is scheduled. \n",
    "# 2024-04-07 20:49:38,065 INFO:   Poll ingress status: Waiting for job service readiness.\n",
    "# 2024-04-07 20:49:58,104 INFO:   Ingress is ready: Job ingress ready, poll ingress success.\n",
    "# 2024-04-07 20:49:58,282 INFO:   Preparing to execute using 1 CSX\n",
    "# 2024-04-07 20:50:26,820 INFO:   About to send initial weights\n",
    "# 2024-04-07 20:51:01,031 INFO:   Finished sending initial weights\n",
    "# 2024-04-07 20:51:01,033 INFO:   Finalizing appliance staging for the run\n",
    "# 2024-04-07 20:51:01,068 INFO:   Waiting for device programming to complete\n",
    "# 2024-04-07 20:52:53,276 INFO:   Device programming is complete\n",
    "# 2024-04-07 20:52:54,190 INFO:   Using network type: ROCE\n",
    "# 2024-04-07 20:52:54,191 INFO:   Waiting for input workers to prime the data pipeline and begin streaming ...\n",
    "# 2024-04-07 20:52:54,237 INFO:   Input workers have begun streaming input data\n",
    "# 2024-04-07 20:53:11,200 INFO:   Appliance staging is complete\n",
    "# 2024-04-07 20:53:11,204 INFO:   Beginning appliance run\n",
    "# 2024-04-07 20:53:32,024 INFO:   | Train Device=CSX, Step=100, Loss=9.48438, Rate=4939.24 samples/sec, GlobalRate=4939.24 samples/sec\n",
    "# 2024-04-07 20:53:53,051 INFO:   | Train Device=CSX, Step=200, Loss=8.35938, Rate=4897.63 samples/sec, GlobalRate=4904.32 samples/sec\n",
    "# 2024-04-07 20:54:13,958 INFO:   | Train Device=CSX, Step=300, Loss=7.91406, Rate=4897.72 samples/sec, GlobalRate=4902.14 samples/sec\n",
    "# 2024-04-07 20:54:34,746 INFO:   | Train Device=CSX, Step=400, Loss=7.54688, Rate=4914.67 samples/sec, GlobalRate=4908.07 samples/sec\n",
    "# 2024-04-07 20:54:55,938 INFO:   | Train Device=CSX, Step=500, Loss=7.46875, Rate=4865.13 samples/sec, GlobalRate=4892.69 samples/sec\n",
    "# 2024-04-07 20:55:17,179 INFO:   | Train Device=CSX, Step=600, Loss=7.39844, Rate=4838.48 samples/sec, GlobalRate=4880.55 samples/sec\n",
    "# 2024-04-07 20:55:38,631 INFO:   | Train Device=CSX, Step=700, Loss=7.35156, Rate=4799.46 samples/sec, GlobalRate=4864.95 samples/sec\n",
    "# 2024-04-07 20:55:59,489 INFO:   | Train Device=CSX, Step=800, Loss=7.25000, Rate=4865.37 samples/sec, GlobalRate=4870.45 samples/sec\n",
    "# 2024-04-07 20:56:20,494 INFO:   | Train Device=CSX, Step=900, Loss=7.21094, Rate=4871.25 samples/sec, GlobalRate=4870.98 samples/sec\n",
    "# 2024-04-07 20:56:41,630 INFO:   | Train Device=CSX, Step=1000, Loss=7.07812, Rate=4855.37 samples/sec, GlobalRate=4868.35 samples/sec\n",
    "# 2024-04-07 20:56:41,631 INFO:   Saving checkpoint at step 1000\n",
    "# 2024-04-07 20:57:17,164 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_1000.mdl\n",
    "# 2024-04-07 20:58:03,021 INFO:   Heartbeat thread stopped for wsjob-fambxt9dpjfxuunmtq4u4t.\n",
    "# 2024-04-07 20:58:03,029 INFO:   Training completed successfully!\n",
    "# 2024-04-07 20:58:03,029 INFO:   Processed 1024000 sample(s) in 210.338430415 seconds.\n",
    "\n",
    "\n",
    "# (venv_cerebras_pt) [swimzebra@cer-login-02 bert]$ python run.py CSX --job_labels name=bert_pt \\--params configs/bert_large_MSL128_sampleds.yaml \\--num_workers_per_csx=1 --mode train \\--model_dir $MODEL_DIR --mount_dirs /home/ /software/ \\--python_paths /home/$(whoami)/R_2.1.1/modelzoo/ \\--compile_dir $(whoami) |& tee mytest.log\n",
    "# 2024-04-07 21:05:28,707 INFO:   Effective batch size is 512.\n",
    "# 2024-04-07 21:05:28,731 INFO:   Checkpoint autoloading is enabled. Looking for latest checkpoint in \"model_dir_bert_large_pytorch\" directory with the following naming convention: `checkpoint_(step)(_timestamp)?.mdl`.\n",
    "# 2024-04-07 21:05:28,732 INFO:   No checkpoints were found in \"model_dir_bert_large_pytorch\".\n",
    "# 2024-04-07 21:05:28,732 INFO:   No checkpoint was provided. Using randomly initialized model parameters.\n",
    "# 2024-04-07 21:05:30,000 INFO:   Saving checkpoint at step 0\n",
    "# 2024-04-07 21:05:57,811 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_0.mdl\n",
    "# 2024-04-07 21:06:11,942 INFO:   Compiling the model. This may take a few minutes.\n",
    "# 2024-04-07 21:06:11,943 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.\n",
    "# 2024-04-07 21:06:13,160 INFO:   Initiating a new image build job against the cluster server.\n",
    "# 2024-04-07 21:06:13,274 INFO:   Custom worker image build is disabled from server.\n",
    "# 2024-04-07 21:06:13,281 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.\n",
    "# 2024-04-07 21:06:13,624 INFO:   Initiating a new compile wsjob against the cluster server.\n",
    "# 2024-04-07 21:06:13,745 INFO:   compile job id: wsjob-at8xgb5rawe2fmk6nqqnwi, remote log path: /n1/wsjob/workdir/job-operator/wsjob-at8xgb5rawe2fmk6nqqnwi\n",
    "# 2024-04-07 21:06:23,792 INFO:   Poll ingress status: Waiting for job service readiness.\n",
    "# 2024-04-07 21:06:53,799 INFO:   Ingress is ready: Job ingress ready, poll ingress success.\n",
    "# 2024-04-07 21:06:57,643 INFO:   Pre-optimization transforms...\n",
    "# 2024-04-07 21:07:03,147 INFO:   Optimizing layouts and memory usage...\n",
    "# 2024-04-07 21:07:03,186 INFO:   Gradient accumulation disabled\n",
    "# 2024-04-07 21:07:07,594 INFO:   Exploring floorplans\n",
    "# 2024-04-07 21:07:10,778 INFO:   Exploring data layouts\n",
    "# 2024-04-07 21:07:45,615 INFO:   Optimizing memory usage\n",
    "# 2024-04-07 21:08:21,159 INFO:   Post-layout optimizations...\n",
    "# 2024-04-07 21:08:32,336 INFO:   Allocating buffers...\n",
    "# 2024-04-07 21:08:34,855 INFO:   Code generation...\n",
    "# 2024-04-07 21:08:48,429 INFO:   Compiling image...\n",
    "# 2024-04-07 21:08:48,434 INFO:   Compiling kernels\n",
    "# 2024-04-07 21:12:11,383 INFO:   Compiling final image\n",
    "# 2024-04-07 21:14:56,767 INFO:   Compile artifacts successfully written to remote compile directory. Compile hash is: cs_6827598271120625226\n",
    "# 2024-04-07 21:14:56,805 INFO:   Heartbeat thread stopped for wsjob-at8xgb5rawe2fmk6nqqnwi.\n",
    "# 2024-04-07 21:14:56,810 INFO:   Compile was successful!\n",
    "# 2024-04-07 21:14:56,816 INFO:   Programming Cerebras Wafer Scale Cluster for execution. This may take a few minutes.\n",
    "# 2024-04-07 21:14:59,176 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.\n",
    "# 2024-04-07 21:14:59,540 INFO:   Initiating a new execute wsjob against the cluster server.\n",
    "# 2024-04-07 21:14:59,674 INFO:   execute job id: wsjob-aevzbtzpk6kdgqtquqsfle, remote log path: /n1/wsjob/workdir/job-operator/wsjob-aevzbtzpk6kdgqtquqsfle\n",
    "# 2024-04-07 21:15:09,721 INFO:   Poll ingress status: Waiting for job running, current job status: Scheduled, msg: job is scheduled. \n",
    "# 2024-04-07 21:15:19,706 INFO:   Poll ingress status: Waiting for job service readiness.\n",
    "# 2024-04-07 21:15:39,747 INFO:   Poll ingress status: Waiting for job ingress readiness.\n",
    "# 2024-04-07 21:15:49,766 INFO:   Ingress is ready: Job ingress ready, poll ingress success.\n",
    "# 2024-04-07 21:15:49,918 INFO:   Preparing to execute using 1 CSX\n",
    "# 2024-04-07 21:16:18,374 INFO:   About to send initial weights\n",
    "# 2024-04-07 21:16:52,486 INFO:   Finished sending initial weights\n",
    "# 2024-04-07 21:16:52,488 INFO:   Finalizing appliance staging for the run\n",
    "# 2024-04-07 21:16:52,509 INFO:   Waiting for device programming to complete\n",
    "# 2024-04-07 21:18:51,034 INFO:   Device programming is complete\n",
    "# 2024-04-07 21:18:51,966 INFO:   Using network type: ROCE\n",
    "# 2024-04-07 21:18:51,967 INFO:   Waiting for input workers to prime the data pipeline and begin streaming ...\n",
    "# 2024-04-07 21:18:51,990 INFO:   Input workers have begun streaming input data\n",
    "# 2024-04-07 21:19:08,716 INFO:   Appliance staging is complete\n",
    "# 2024-04-07 21:19:08,722 INFO:   Beginning appliance run\n",
    "# 2024-04-07 21:19:26,094 INFO:   | Train Device=CSX, Step=100, Loss=9.39062, Rate=2966.30 samples/sec, GlobalRate=2966.30 samples/sec\n",
    "# 2024-04-07 21:19:43,531 INFO:   | Train Device=CSX, Step=200, Loss=8.70312, Rate=2948.35 samples/sec, GlobalRate=2951.27 samples/sec\n",
    "# 2024-04-07 21:20:00,929 INFO:   | Train Device=CSX, Step=300, Loss=7.79688, Rate=2944.98 samples/sec, GlobalRate=2948.42 samples/sec\n",
    "# 2024-04-07 21:20:18,725 INFO:   | Train Device=CSX, Step=400, Loss=7.39062, Rate=2904.25 samples/sec, GlobalRate=2930.26 samples/sec\n",
    "# 2024-04-07 21:20:36,484 INFO:   | Train Device=CSX, Step=500, Loss=7.80469, Rate=2891.48 samples/sec, GlobalRate=2920.68 samples/sec\n",
    "# 2024-04-07 21:20:54,166 INFO:   | Train Device=CSX, Step=600, Loss=7.53125, Rate=2893.99 samples/sec, GlobalRate=2916.48 samples/sec\n",
    "# 2024-04-07 21:21:11,723 INFO:   | Train Device=CSX, Step=700, Loss=7.35156, Rate=2907.35 samples/sec, GlobalRate=2916.45 samples/sec\n",
    "# 2024-04-07 21:21:29,460 INFO:   | Train Device=CSX, Step=800, Loss=7.27344, Rate=2894.92 samples/sec, GlobalRate=2912.69 samples/sec\n",
    "# 2024-04-07 21:21:46,882 INFO:   | Train Device=CSX, Step=900, Loss=7.35938, Rate=2921.25 samples/sec, GlobalRate=2915.57 samples/sec\n",
    "# 2024-04-07 21:22:04,470 INFO:   | Train Device=CSX, Step=1000, Loss=7.12500, Rate=2915.13 samples/sec, GlobalRate=2915.11 samples/sec\n",
    "# 2024-04-07 21:22:04,471 INFO:   Saving checkpoint at step 1000\n",
    "# 2024-04-07 21:22:39,924 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_1000.mdl\n",
    "# 2024-04-07 21:23:16,411 INFO:   Heartbeat thread stopped for wsjob-aevzbtzpk6kdgqtquqsfle.\n",
    "# 2024-04-07 21:23:16,418 INFO:   Training completed successfully!\n",
    "# 2024-04-07 21:23:16,418 INFO:   Processed 512000 sample(s) in 175.636380857 seconds.\n",
    "\n",
    "\n",
    "# (venv_cerebras_pt) [swimzebra@cer-login-02 bert]$ python run.py CSX --job_labels name=bert_pt \\--params configs/bert_large_MSL128_sampleds.yaml \\--num_workers_per_csx=1 --mode train \\--model_dir $MODEL_DIR --mount_dirs /home/ /software/ \\--python_paths /home/$(whoami)/R_2.1.1/modelzoo/ \\--compile_dir $(whoami) |& tee mytest.log\n",
    "# 2024-04-07 21:40:10,495 INFO:   Effective batch size is 2048.\n",
    "# 2024-04-07 21:40:10,520 INFO:   Checkpoint autoloading is enabled. Looking for latest checkpoint in \"model_dir_bert_large_pytorch\" directory with the following naming convention: `checkpoint_(step)(_timestamp)?.mdl`.\n",
    "# 2024-04-07 21:40:10,521 INFO:   No checkpoints were found in \"model_dir_bert_large_pytorch\".\n",
    "# 2024-04-07 21:40:10,521 INFO:   No checkpoint was provided. Using randomly initialized model parameters.\n",
    "# 2024-04-07 21:40:11,831 INFO:   Saving checkpoint at step 0\n",
    "# 2024-04-07 21:40:39,656 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_0.mdl\n",
    "# 2024-04-07 21:40:54,883 INFO:   Compiling the model. This may take a few minutes.\n",
    "# 2024-04-07 21:40:54,884 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.\n",
    "# 2024-04-07 21:40:56,121 INFO:   Initiating a new image build job against the cluster server.\n",
    "# 2024-04-07 21:40:56,241 INFO:   Custom worker image build is disabled from server.\n",
    "# 2024-04-07 21:40:56,247 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.\n",
    "# 2024-04-07 21:40:56,605 INFO:   Initiating a new compile wsjob against the cluster server.\n",
    "# 2024-04-07 21:40:56,729 INFO:   compile job id: wsjob-4fcubhrlaasxytczm9xks2, remote log path: /n1/wsjob/workdir/job-operator/wsjob-4fcubhrlaasxytczm9xks2\n",
    "# 2024-04-07 21:41:06,779 INFO:   Poll ingress status: Waiting for job service readiness.\n",
    "# 2024-04-07 21:41:36,773 INFO:   Poll ingress status: Waiting for job ingress readiness.\n",
    "# 2024-04-07 21:41:46,785 INFO:   Ingress is ready: Job ingress ready, poll ingress success.\n",
    "# 2024-04-07 21:41:50,920 INFO:   Pre-optimization transforms...\n",
    "# 2024-04-07 21:41:56,749 INFO:   Optimizing layouts and memory usage...\n",
    "# 2024-04-07 21:41:56,857 INFO:   Gradient accumulation disabled\n",
    "# 2024-04-07 21:42:01,815 INFO:   Exploring floorplans\n",
    "# 2024-04-07 21:42:03,676 INFO:   Exploring data layouts\n",
    "# 2024-04-07 21:42:39,420 INFO:   Optimizing memory usage\n",
    "# 2024-04-07 21:43:30,347 INFO:   Post-layout optimizations...\n",
    "# 2024-04-07 21:43:37,996 INFO:   Allocating buffers...\n",
    "# 2024-04-07 21:43:40,827 INFO:   Code generation...\n",
    "# 2024-04-07 21:43:56,746 INFO:   Compiling image...\n",
    "# 2024-04-07 21:43:56,752 INFO:   Compiling kernels\n",
    "# 2024-04-07 21:45:53,349 INFO:   Compiling final image\n",
    "# 2024-04-07 21:48:20,641 INFO:   Compile artifacts successfully written to remote compile directory. Compile hash is: cs_9917087188979144796\n",
    "# 2024-04-07 21:48:20,685 INFO:   Heartbeat thread stopped for wsjob-4fcubhrlaasxytczm9xks2.\n",
    "# 2024-04-07 21:48:20,687 INFO:   Compile was successful!\n",
    "# 2024-04-07 21:48:20,694 INFO:   Programming Cerebras Wafer Scale Cluster for execution. This may take a few minutes.\n",
    "# 2024-04-07 21:48:23,441 INFO:   Defaulted to use the job-operator namespace as the usernode config /opt/cerebras/config_v2 only has access to that namespace.\n",
    "# 2024-04-07 21:48:23,828 INFO:   Initiating a new execute wsjob against the cluster server.\n",
    "# 2024-04-07 21:48:23,974 INFO:   execute job id: wsjob-kjqmafhcqncatbvpav2drt, remote log path: /n1/wsjob/workdir/job-operator/wsjob-kjqmafhcqncatbvpav2drt\n",
    "# 2024-04-07 21:48:34,026 INFO:   Poll ingress status: Waiting for job running, current job status: Queueing, msg: job is queueing. Job queue status: current job is top of queue but likely blocked by running jobs, 1 execute job(s) running using 1 system(s), 1 compile job(s) running using 67Gi memory. For more information, please run 'csctl get jobs'.\n",
    "# 2024-04-07 21:48:43,993 INFO:   Poll ingress status: Waiting for job running, current job status: Scheduled, msg: job is scheduled. \n",
    "# 2024-04-07 21:48:54,014 INFO:   Poll ingress status: Waiting for job service readiness.\n",
    "# 2024-04-07 21:49:14,053 INFO:   Ingress is ready: Job ingress ready, poll ingress success.\n",
    "# 2024-04-07 21:49:14,243 INFO:   Preparing to execute using 1 CSX\n",
    "# 2024-04-07 21:49:45,206 INFO:   About to send initial weights\n",
    "# 2024-04-07 21:50:18,979 INFO:   Finished sending initial weights\n",
    "# 2024-04-07 21:50:18,981 INFO:   Finalizing appliance staging for the run\n",
    "# 2024-04-07 21:50:19,028 INFO:   Waiting for device programming to complete\n",
    "# 2024-04-07 21:52:07,041 INFO:   Device programming is complete\n",
    "# 2024-04-07 21:52:08,037 INFO:   Using network type: ROCE\n",
    "# 2024-04-07 21:52:08,038 INFO:   Waiting for input workers to prime the data pipeline and begin streaming ...\n",
    "# 2024-04-07 21:52:08,087 INFO:   Input workers have begun streaming input data\n",
    "# 2024-04-07 21:52:25,192 INFO:   Appliance staging is complete\n",
    "# 2024-04-07 21:52:25,197 INFO:   Beginning appliance run\n",
    "# 2024-04-07 21:52:55,237 INFO:   | Train Device=CSX, Step=100, Loss=9.48438, Rate=6837.58 samples/sec, GlobalRate=6837.59 samples/sec\n",
    "# 2024-04-07 21:53:25,567 INFO:   | Train Device=CSX, Step=200, Loss=8.48438, Rate=6786.52 samples/sec, GlobalRate=6794.77 samples/sec\n",
    "# 2024-04-07 21:53:56,185 INFO:   | Train Device=CSX, Step=300, Loss=7.77344, Rate=6727.93 samples/sec, GlobalRate=6759.10 samples/sec\n",
    "# 2024-04-07 21:54:26,598 INFO:   | Train Device=CSX, Step=400, Loss=7.64062, Rate=6731.56 samples/sec, GlobalRate=6752.80 samples/sec\n",
    "# 2024-04-07 21:54:57,293 INFO:   | Train Device=CSX, Step=500, Loss=7.37500, Rate=6695.85 samples/sec, GlobalRate=6736.49 samples/sec\n",
    "# 2024-04-07 21:55:27,961 INFO:   | Train Device=CSX, Step=600, Loss=7.42188, Rate=6685.16 samples/sec, GlobalRate=6726.68 samples/sec\n",
    "# 2024-04-07 21:55:58,204 INFO:   | Train Device=CSX, Step=700, Loss=7.25000, Rate=6737.13 samples/sec, GlobalRate=6733.08 samples/sec\n",
    "# 2024-04-07 21:56:28,653 INFO:   | Train Device=CSX, Step=800, Loss=7.12500, Rate=6730.36 samples/sec, GlobalRate=6732.18 samples/sec\n",
    "# 2024-04-07 21:56:58,906 INFO:   | Train Device=CSX, Step=900, Loss=7.25000, Rate=6753.95 samples/sec, GlobalRate=6736.32 samples/sec\n",
    "# 2024-04-07 21:57:29,431 INFO:   | Train Device=CSX, Step=1000, Loss=7.14844, Rate=6727.09 samples/sec, GlobalRate=6733.60 samples/sec\n",
    "# 2024-04-07 21:57:29,432 INFO:   Saving checkpoint at step 1000\n",
    "# 2024-04-07 21:58:04,907 INFO:   Saved checkpoint model_dir_bert_large_pytorch/checkpoint_1000.mdl\n",
    "# 2024-04-07 21:59:00,127 INFO:   Heartbeat thread stopped for wsjob-kjqmafhcqncatbvpav2drt.\n",
    "# 2024-04-07 21:59:00,135 INFO:   Training completed successfully!\n",
    "# 2024-04-07 21:59:00,136 INFO:   Processed 2048000 sample(s) in 304.146350184 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9789d6",
   "metadata": {},
   "source": [
    "Groq log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdddddc",
   "metadata": {},
   "source": [
    "| Scenario                            | Source   | Accuracy | E2E Latency (ms) | E2E IPS | On-Chip Latency (ms) | On-Chip IPS |\n",
    "|-------------------------------------|----------|----------|-------------------|---------|----------------------|-------------|\n",
    "| Seq. Length: 128, Batch Size: 1     | CPU      | 77.47%   | 2.21              | 451.69  | --                   | --          |\n",
    "| Seq. Length: 128, Batch Size: 1     | GroqChip | 77.47%   | 0.07              | 15121.15| 0.03                 | 37576.72    |\n",
    "| Seq. Length: 256, Batch Size: 1     | CPU      | 77.47%   | 4.09              | 244.35  | --                   | --          |\n",
    "| Seq. Length: 256, Batch Size: 1     | GroqChip | 77.47%   | 0.08              | 12364.87| 0.04                 | 23391.20    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fea01ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run with dummy inputs:\n",
    "# batch_size = 1, sequence_length = 128\n",
    "\n",
    "# (groqflow) swimzebra@groq-r01-gn-08:~/groqflow/proof_points/natural_language_processing/bert$ python bert_tiny.py\n",
    "# tokenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████| 346/346 [00:00<00:00, 4.07MB/s]\n",
    "# vocab.txt: 100%|███████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 6.56MB/s]\n",
    "# special_tokens_map.json: 100%|███████████████████████████████████████████████████████████████████████████| 112/112 [00:00<00:00, 1.75MB/s]\n",
    "# config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████| 760/760 [00:00<00:00, 10.3MB/s]\n",
    "# pytorch_model.bin: 100%|██████████████████████████████████████████████████████████████████████████████| 17.6M/17.6M [00:00<00:00, 120MB/s]\n",
    "# /home/swimzebra/miniconda3/envs/groqflow/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
    "#   return self.fget.__get__(instance, owner)()\n",
    "\n",
    "\n",
    "\n",
    "# Building \"bert_tiny\"\n",
    "#     ✓ Exporting PyTorch to ONNX\n",
    "#     ✓ Optimizing ONNX file\n",
    "#     ✓ Checking for Op support\n",
    "#     ✓ Converting to FP16\n",
    "#     ✓ Compiling model\n",
    "#     ✓ Assembling model\n",
    "\n",
    "# Woohoo! Saved to ~/.cache/groqflow/bert_tiny\n",
    "# Preprocessing data.\n",
    "# /home/swimzebra/miniconda3/envs/groqflow/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for sst contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/sst\n",
    "# You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
    "# Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
    "#   warnings.warn(\n",
    "# Downloading builder script: 100%|████████████████████████████████████████████████████████████████████| 9.13k/9.13k [00:00<00:00, 35.7MB/s]\n",
    "# Downloading readme: 100%|████████████████████████████████████████████████████████████████████████████| 6.68k/6.68k [00:00<00:00, 34.8MB/s]\n",
    "# Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████| 6.37M/6.37M [00:01<00:00, 5.15MB/s]\n",
    "# Downloading data: 100%|████████████████████████████████████████████████████████████████████████████████| 790k/790k [00:00<00:00, 1.51MB/s]\n",
    "# Generating train split: 100%|███████████████████████████████████████████████████████████████| 8544/8544 [00:00<00:00, 11163.25 examples/s]\n",
    "# Generating validation split: 100%|███████████████████████████████████████████████████████████| 1101/1101 [00:00<00:00, 2032.19 examples/s]\n",
    "# Generating test split: 100%|█████████████████████████████████████████████████████████████████| 2210/2210 [00:00<00:00, 3963.05 examples/s]\n",
    "\n",
    "# Info: No inputs received for benchmark. Using the inputs provided during model compilation.\n",
    "# Running inference on GroqChip.\n",
    "# Running inference using PyTorch model (CPU).\n",
    "# 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 2210/2210 [00:04<00:00, 451.76it/s]\n",
    "# +--------+----------+-------------------------+----------------+----------------------+-------------+\n",
    "# | Source | Accuracy | end-to-end latency (ms) | end-to-end IPS | on-chip latency (ms) | on-chip IPS |\n",
    "# +--------+----------+-------------------------+----------------+----------------------+-------------+\n",
    "# |  cpu   |  77.47%  |           2.21          |     451.69     |          --          |      --     |\n",
    "# |  groq  |  77.47%  |           0.07          |    15121.15    |         0.03         |   37576.72  |\n",
    "# +--------+----------+-------------------------+----------------+----------------------+-------------+\n",
    "# Proof point /home/swimzebra/groqflow/proof_points/natural_language_processing/bert/bert_tiny.py finished!\n",
    "\n",
    "\n",
    "# #Run with custom inputs:\n",
    "# batch_size = 1, sequence_length = 256\n",
    "# (groqflow) swimzebra@groq-r01-gn-08:~/groqflow/proof_points/natural_language_processing/bert$ vi bert_tiny.py\n",
    "# (groqflow) swimzebra@groq-r01-gn-08:~/groqflow/proof_points/natural_language_processing/bert$ python bert_tiny.py\n",
    "# /home/swimzebra/miniconda3/envs/groqflow/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
    "#   return self.fget.__get__(instance, owner)()\n",
    "\n",
    "# Warning: build_model() discovered a cached build of bert_tiny, but decided to rebuild for the following reasons:\n",
    "\n",
    "#          - Input shape of model \"bert_tiny\" changed from {'attention_mask': (1, 128), 'input_ids': (1, 128)} to {'attention_mask': (1, 256), 'input_ids': (1, 256)} since the last time it was built.\n",
    "\n",
    "#          build_model() will now rebuild your model to ensure correctness. You can change this policy by setting the build_model(rebuild=...) argument.\n",
    "\n",
    "\n",
    "\n",
    "# Building \"bert_tiny\"\n",
    "#     ✓ Exporting PyTorch to ONNX\n",
    "#     ✓ Optimizing ONNX file\n",
    "#     ✓ Checking for Op support\n",
    "#     ✓ Converting to FP16\n",
    "#     ✓ Compiling model\n",
    "#     ✓ Assembling model\n",
    "\n",
    "# Woohoo! Saved to ~/.cache/groqflow/bert_tiny\n",
    "# Preprocessing data.\n",
    "# /home/swimzebra/miniconda3/envs/groqflow/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for sst contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/sst\n",
    "# You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
    "# Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
    "#   warnings.warn(\n",
    "\n",
    "# Info: No inputs received for benchmark. Using the inputs provided during model compilation.\n",
    "# Running inference on GroqChip.\n",
    "# Running inference using PyTorch model (CPU).\n",
    "# 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 2210/2210 [00:09<00:00, 244.43it/s]\n",
    "# +--------+----------+-------------------------+----------------+----------------------+-------------+\n",
    "# | Source | Accuracy | end-to-end latency (ms) | end-to-end IPS | on-chip latency (ms) | on-chip IPS |\n",
    "# +--------+----------+-------------------------+----------------+----------------------+-------------+\n",
    "# |  cpu   |  77.47%  |           4.09          |     244.35     |          --          |      --     |\n",
    "# |  groq  |  77.47%  |           0.08          |    12364.87    |         0.04         |   23391.20  |\n",
    "# +--------+----------+-------------------------+----------------+----------------------+-------------+\n",
    "# Proof point /home/swimzebra/groqflow/proof_points/natural_language_processing/bert/bert_tiny.py finished!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9792ca52",
   "metadata": {},
   "source": [
    "Graphcore log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef4b98",
   "metadata": {},
   "source": [
    "| Learning Rate | Epochs | Batch Size | Test Batch Size | Accuracy on Test Set |\n",
    "|---------------|--------|------------|-----------------|----------------------|\n",
    "| 0.05          | 10     | 8          | 80              | 98.22%               |\n",
    "| 0.01          | 100    | 32         | 80              | 99.11%               |\n",
    "| 0.01          | 100    | 256        | 80              | 98.05%               |\n",
    "| 0.001         | 100    | 32         | 80              | 98.25%               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eb3d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (poptorch33_env) (base) swimzebra@gc-poplar-03:~/graphcore/examples/tutorials/simple_applications/pytorch/mnist$ /opt/slurm/bin/srun --ipus=1 python mnist_poptorch.py\n",
    "# srun: job 21004 queued and waiting for resources\n",
    "# srun: job 21004 has been allocated resources\n",
    "# 100%|██████████| 9912422/9912422 [00:00<00:00, 345230062.89it/s]\n",
    "# 100%|██████████| 28881/28881 [00:00<00:00, 208136930.97it/s]\n",
    "# 100%|██████████| 1648877/1648877 [00:00<00:00, 50293734.25it/s]\n",
    "# 100%|██████████| 4542/4542 [00:00<00:00, 14421293.54it/s]\n",
    "# Epochs:   0%|          | 0/10 [00:00<?,[22:25:32.033] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 10\n",
    "# Graph compilation: 100%|██████████| 100/100 [00:21<00:00]\n",
    "# Epochs: 100%|██████████| 10/10 [01:47<00:00, 10.74s/it]\n",
    "# Graph compilation: 100%|██████████| 100/100 [00:14<00:00]                          \n",
    "#  94%|███████�Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
    "# Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /home/swimzebra/.torch/datasets/MNIST/raw/train-images-idx3-ubyte.gz\n",
    "# Extracting /home/swimzebra/.torch/datasets/MNIST/raw/train-images-idx3-ubyte.gz to /home/swimzebra/.torch/datasets/MNIST/raw\n",
    "\n",
    "# Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
    "# Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /home/swimzebra/.torch/datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n",
    "# Extracting /home/swimzebra/.torch/datasets/MNIST/raw/train-labels-idx1-ubyte.gz to /home/swimzebra/.torch/datasets/MNIST/raw\n",
    "\n",
    "# Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
    "# Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /home/swimzebra/.torch/datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
    "# Extracting /home/swimzebra/.torch/datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to /home/swimzebra/.torch/datasets/MNIST/raw\n",
    "\n",
    "# Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
    "# Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /home/swimzebra/.torch/datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
    "# Extracting /home/swimzebra/.torch/datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to /home/swimzebra/.torch/datasets/MNIST/raw\n",
    "\n",
    "# TrainingModelWithLoss(\n",
    "#   (model): Network(\n",
    "#     (layer1): Block(\n",
    "#       (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
    "#       (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#       (relu): ReLU()\n",
    "#     )\n",
    "#     (layer2): Block(\n",
    "#       (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
    "#       (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#       (relu): ReLU()\n",
    "#     )\n",
    "#     (layer3): Linear(in_features=1600, out_features=128, bias=True)\n",
    "#     (layer3_act): ReLU()\n",
    "#     (layer3_dropout): Dropout(p=0.5, inplace=False)\n",
    "#     (layer4): Linear(in_features=128, out_features=10, bias=True)\n",
    "#     (softmax): Softmax(dim=1)\n",
    "#   )\n",
    "#   (loss): CrossEntropyLoss()\n",
    "# )\n",
    "# Accuracy on test set: 98.53%\n",
    "\n",
    "# (poptorch33_env) (base) swimzebra@gc-poplar-03:~/graphcore/examples/tutorials/simple_applications/pytorch/mnist$ /opt/slurm/bin/srun --ipus=1 python mnist_poptorch.py\n",
    "# srun: job 21005 queued and waiting for resources\n",
    "# srun: job 21005 has been allocated resources\n",
    "# Epochs:   0%|          | 0/10 [00:00<?,[22:35:38.220] [poptorch:cpp] [warning] [DISPATCHER] Type coerced from Long to Int for tensor id 10\n",
    "# Graph compilation: 100%|██████████| 100/100 [00:22<00:00]\n",
    "# Epochs: 100%|██████████| 10/10 [01:51<00:00, 11.13s/it]\n",
    "# Graph compilation: 100%|██████████| 100/100 [00:14<00:00]                          \n",
    "#  95%|██████�TrainingModelWithLoss(:00, 14.34it/s]<00:00]\n",
    "# Accuracy on test set: 98.02%\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5206ed12",
   "metadata": {},
   "source": [
    "Sambanova Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1354852",
   "metadata": {},
   "source": [
    "| n_tasks | Duration |\n",
    "|---------|----------|\n",
    "| 2       | 784      |\n",
    "| 4       | 785      |\n",
    "| 8       | 789      |\n",
    "| 16      | 807      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8735be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPILE END AT 789\n",
    "# RUN\n",
    "# SHELL=/bin/bash\n",
    "# CONDA_EXE=/home/swimzebra/miniconda3/bin/conda\n",
    "# _CE_M=\n",
    "# PWD=/home/swimzebra/BertLarge\n",
    "# LOGNAME=swimzebra\n",
    "# OPENBLAS_NUM_THREADS=8\n",
    "# MOTD_SHOWN=pam\n",
    "# HOME=/home/swimzebra\n",
    "# LANG=en_US.UTF-8\n",
    "# VIRTUAL_ENV=/opt/sambaflow/apps/nlp/transformers_on_rdu/venv\n",
    "# SSH_CONNECTION=140.221.69.48 55042 140.221.82.9 22\n",
    "# TERM=xterm-256color\n",
    "# _CE_CONDA=\n",
    "# LIBVIRT_DEFAULT_URI=qemu:///system\n",
    "# USER=swimzebra\n",
    "# CONDA_SHLVL=0\n",
    "# IBV_FORK_SAFE=1\n",
    "# SHLVL=2\n",
    "# SOFTWARE_HOME=/opt\n",
    "# CONDA_PYTHON_EXE=/home/swimzebra/miniconda3/bin/python\n",
    "# PS1=(venv) \n",
    "# SSH_CLIENT=140.221.69.48 55042 22\n",
    "# SN_NUM_THREADS=32\n",
    "# OMP_NUM_THREADS=18\n",
    "# XDG_DATA_DIRS=/usr/local/share:/usr/share:/var/lib/snapd/desktop\n",
    "# PATH=/opt/sambaflow/apps/nlp/transformers_on_rdu/venv/bin:/home/swimzebra/miniconda3/condabin:/opt/sambaflow/bin:/opt/sambaflow/venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/swimzebra/.local/bin:/home/swimzebra/bin\n",
    "# GLIBC_TUNABLES=glibc.cpu.hwcaps=-AVX_Usable,-AVX2_Usable,-Prefer_ERMS,-Prefer_FSRM,Prefer_No_AVX512,Prefer_No_VZEROUPPER,-AVX_Fast_Unaligned_Load,-ERMS\n",
    "# SSH_TTY=/dev/pts/3\n",
    "# OLDPWD=/home/swimzebra\n",
    "# _=/usr/bin/env\n",
    "# Submitted batch job 30786\n",
    "# Machine state After: \n",
    "# Platform: DataScale SN30-8\n",
    "\n",
    "# Physical Inventory:\n",
    "# Component Name                        | Serial Number       | Inventory State | Functional State\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# /NODE/XRDU_0/RDU_0                    | 60287B316ABDB895    | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/DDRCH_0/DIMM_A0    | 1F5BCAD             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/DDRCH_1/DIMM_B0    | 1F5BDD0             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/DDRCH_2/DIMM_E0    | 1F6CF93             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/DDRCH_3/DIMM_F0    | 1F6CF2F             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/DDRCH_4/DIMM_G0    | 1F5BAED             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/DDRCH_5/DIMM_H0    | 1F5BCA8             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/DDRCH_6/DIMM_C0    | 1F5BBD0             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/DDRCH_7/DIMM_D0    | 1F5BBD1             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/PCIE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/PCIE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/PCIE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/PCIE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/PCIE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/PCIE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/TILE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/TILE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/TILE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/TILE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/TILE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/TILE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/TILE_6             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_0/TILE_7             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1                    | 206043316ABDB895    | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/DDRCH_0/DIMM_J0    | 1F6D120             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/DDRCH_1/DIMM_K0    | 1F6D0FC             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/DDRCH_2/DIMM_N0    | 1F6CE6C             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/DDRCH_3/DIMM_P0    | 1F6CE38             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/DDRCH_4/DIMM_Q0    | 1F5BBC4             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/DDRCH_5/DIMM_R0    | 1F5BCE3             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/DDRCH_6/DIMM_L0    | 1F2E05D             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/DDRCH_7/DIMM_M0    | 1F312FB             | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/PCIE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/PCIE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/PCIE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/PCIE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/PCIE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/PCIE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/TILE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/TILE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/TILE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/TILE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/TILE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/TILE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/TILE_6             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/RDU_1/TILE_7             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/SW_0                     | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/SW_0/PORT_0              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/SW_0/PORT_1              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/SW_0/PORT_2              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/SW_0/PORT_3              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/SW_0/PORT_4              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/SW_0/PORT_5              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/SW_0/PORT_6              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/SW_0/PORT_7              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_0/SW_0/PORT_8              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0                    | 6050747469B35895    | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/DDRCH_0/DIMM_A0    | 1F5BC75             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/DDRCH_1/DIMM_B0    | 1F5BC74             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/DDRCH_2/DIMM_E0    | 1F5BC77             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/DDRCH_3/DIMM_F0    | 1F6F7E5             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/DDRCH_4/DIMM_G0    | 1F6F6A8             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/DDRCH_5/DIMM_H0    | 1F6F846             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/DDRCH_6/DIMM_C0    | 1F6F76E             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/DDRCH_7/DIMM_D0    | 1F6F872             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/PCIE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/PCIE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/PCIE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/PCIE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/PCIE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/PCIE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/TILE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/TILE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/TILE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/TILE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/TILE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/TILE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/TILE_6             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_0/TILE_7             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1                    | 2048347469B35895    | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/DDRCH_0/DIMM_J0    | 1F73AB8             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/DDRCH_1/DIMM_K0    | 1F73AB9             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/DDRCH_2/DIMM_N0    | 1F5BADA             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/DDRCH_3/DIMM_P0    | 1F5BACA             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/DDRCH_4/DIMM_Q0    | 1F5BBC6             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/DDRCH_5/DIMM_R0    | 1F5BBD6             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/DDRCH_6/DIMM_L0    | 1F5BC2A             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/DDRCH_7/DIMM_M0    | 1F5BC87             | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/PCIE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/PCIE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/PCIE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/PCIE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/PCIE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/PCIE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/TILE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/TILE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/TILE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/TILE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/TILE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/TILE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/TILE_6             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/RDU_1/TILE_7             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/SW_0                     | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/SW_0/PORT_0              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/SW_0/PORT_1              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/SW_0/PORT_2              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/SW_0/PORT_3              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/SW_0/PORT_4              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/SW_0/PORT_5              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/SW_0/PORT_6              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/SW_0/PORT_7              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_1/SW_0/PORT_8              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0                    | 504872B16ABDB895    | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/DDRCH_0/DIMM_A0    | 1F5BC38             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/DDRCH_1/DIMM_B0    | 1F5BC86             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/DDRCH_2/DIMM_E0    | 1F5BC76             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/DDRCH_3/DIMM_F0    | 1F5BD78             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/DDRCH_4/DIMM_G0    | 1F5BAEE             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/DDRCH_5/DIMM_H0    | 1F5BC13             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/DDRCH_6/DIMM_C0    | 1F5BD5A             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/DDRCH_7/DIMM_D0    | 1F5BDB9             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/PCIE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/PCIE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/PCIE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/PCIE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/PCIE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/PCIE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/TILE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/TILE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/TILE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/TILE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/TILE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/TILE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/TILE_6             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_0/TILE_7             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1                    | 8304AB16ABDB895     | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/DDRCH_0/DIMM_J0    | 1F5BC7C             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/DDRCH_1/DIMM_K0    | 1F5BC2D             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/DDRCH_2/DIMM_N0    | 1F5BC81             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/DDRCH_3/DIMM_P0    | 1F5BC82             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/DDRCH_4/DIMM_Q0    | 1F5BBBA             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/DDRCH_5/DIMM_R0    | 1F5BB0D             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/DDRCH_6/DIMM_L0    | 1F5BBAE             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/DDRCH_7/DIMM_M0    | 1F5BD87             | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/PCIE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/PCIE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/PCIE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/PCIE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/PCIE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/PCIE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/TILE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/TILE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/TILE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/TILE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/TILE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/TILE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/TILE_6             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/RDU_1/TILE_7             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/SW_0                     | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/SW_0/PORT_0              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/SW_0/PORT_1              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/SW_0/PORT_2              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/SW_0/PORT_3              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/SW_0/PORT_4              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/SW_0/PORT_5              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/SW_0/PORT_6              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/SW_0/PORT_7              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_2/SW_0/PORT_8              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0                    | 500838B469B35895    | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/DDRCH_0/DIMM_A0    | 1F6CFC0             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/DDRCH_1/DIMM_B0    | 1F6CEAF             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/DDRCH_2/DIMM_E0    | 1F6CF06             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/DDRCH_3/DIMM_F0    | 1F6CE44             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/DDRCH_4/DIMM_G0    | 1F5BD38             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/DDRCH_5/DIMM_H0    | 1F5BAFF             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/DDRCH_6/DIMM_C0    | 1F5BD6D             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/DDRCH_7/DIMM_D0    | 1F5BB79             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/PCIE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/PCIE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/PCIE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/PCIE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/PCIE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/PCIE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/TILE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/TILE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/TILE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/TILE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/TILE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/TILE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/TILE_6             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_0/TILE_7             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1                    | 700834B469B35895    | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/DDRCH_0/DIMM_J0    | 1F6CE64             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/DDRCH_1/DIMM_K0    | 1F6D121             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/DDRCH_2/DIMM_N0    | 1F6D114             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/DDRCH_3/DIMM_P0    | 1F6CE60             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/DDRCH_4/DIMM_Q0    | 1F5BDD7             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/DDRCH_5/DIMM_R0    | 1F5BDD3             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/DDRCH_6/DIMM_L0    | 1F6CFFB             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/DDRCH_7/DIMM_M0    | 1F5BBA3             | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/PCIE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/PCIE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/PCIE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/PCIE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/PCIE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/PCIE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/TILE_0             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/TILE_1             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/TILE_2             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/TILE_3             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/TILE_4             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/TILE_5             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/TILE_6             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/RDU_1/TILE_7             | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/SW_0                     | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/SW_0/PORT_0              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/SW_0/PORT_1              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/SW_0/PORT_2              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/SW_0/PORT_3              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/SW_0/PORT_4              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/SW_0/PORT_5              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/SW_0/PORT_6              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/SW_0/PORT_7              | N/A                 | Present         | Online       \n",
    "# /NODE/XRDU_3/SW_0/PORT_8              | N/A                 | Present         | Online       \n",
    "# /NODE/HOST/HIC_0/DPORT                | N/A                 | Present         | Online       \n",
    "# /NODE/HOST/HIC_1/DPORT                | N/A                 | Present         | Online       \n",
    "# /NODE/HOST/HIC_2/DPORT                | N/A                 | Present         | Online       \n",
    "# /NODE/HOST/HIC_3/DPORT                | N/A                 | Present         | Online\n",
    "# Duration:  789"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience/conda-2023-01-10",
   "language": "python",
   "name": "conda-2023-01-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
